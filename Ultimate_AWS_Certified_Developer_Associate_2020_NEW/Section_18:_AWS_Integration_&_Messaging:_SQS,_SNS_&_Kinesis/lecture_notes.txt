AWS Integration & Messaging - Section Introduction
If you want to deploy multiple applications.



Introduction to Messaging

Section Introduction

-When we start deploying multiple applications, they will
 inevitably need to communicate with one other



-There are two patterns of applications communication

  1) Synchronous communications(application to application)

  2) Asynchronous / Event based 
    (application to queue to application)


-Synchronous between applications can be problematic if there
 are sudden spikes of traffic

-What if you need to suddenly encode 100 videos but usually
 it's 10?


-In that case, it's better to decouple your applications,
 -using SQS: queue model
 -using SNS: pub/sub model
 -using Kinesis: real-time streaming model

-These services can scale independently from our application!



Amazon SQS - Standard Queues

What's a queue?
Contain messages into our sqs queue.
Many producer sending messages to the SQS queue.
Consumer will pull from the queue.
Process it and poll messages.


Amazon SQS - Standard Queue
-Oldest offering (over 10 years old)
-Fully managed service, used to decouple applications

-Attributes:
 -Unlimited throughput unlimited number of messages in queue
 -Default retention of messages: 4 days, maximum of 14 days
 -Low latency (<10 ms on publish and recieve)
 -Limitation of 256KB message sent
 
-Can have duplicate messages 
 (at least once delivery, occasionally)

-Can have out of order messages 
 (best effort ordering)


SQS - Producing Messages
-Produced to SQS using the SDK (SendMessage API)
-The message is persisted in SQS until a consumer deletes it
-Message retention: default 4 days, up to 14 days

-Example: send an order to be processed
 -Order id
 -Customer id
 -Any attributes you want

-SQS standard: unlimited throughput


SQS - Consuming Messages
-Consumers (running on EC2 instances, servers, or AWS Lambda)...

-Poll SQS for messages (recieve up to 10 messages at a time)

-Process the messages 
 (example: insert the message into an RDS database)

-Delete the messages using the DeleteMessage API



SQS - Multiple EC2 Instances Consumers
-Consumers recieve and process messages in parallel

-At least once delivery

-Best-effort message ordering

-Consumers delete messages after processing them

-We can scale consumers horizontally to improve
 throughput of processing



SQS with Auto Scaling Group (ASG)
Auto Scaling Group must be scaling on some metrics.
We can set up an alarm and this would lead to more
scaling to your auto scaling group


SQS to decouple between applications tiers
We have front-end web app.
Processing may slow down the website.
We can decouple this into different applications.
Backend take from the SQS queue.
front-end and Backend has their own Auto Scaling.



Amazon SQS - Security
-Encryption:
 -In-flight encryption using HTTPS API
 -At-rest encryption using KMS keys
 -Client-side encryption if the client wants to
  perform encryption/decryption itself

-Access Controls: IAM policies to regulate access
 to the SQS API

-SQS Access Controls:(similar to S3 bucket policies)
 -Useful for cross-account access to SQS queues
 -Useful for allowing other services (SNS, S3...)
  to write to an SQS queue





SQS - Standard Queue Hands On
When we create a queue we have a standard
We can set the queue between 4 to 14 days.

Access policy.
Set others accounts.
Helpful when we do some integrations.
Enable a server side encryption.
Poll for the message.



SQS - Message Visibility Timeout
-After a message is polled by a consumer,
 it becomes invisible to other consumers

-By default, the "message visibility timeout" is 30 seconds

-That means the message has 30 seconds to be processed

-After the message visibility timeout is over,
 the message is "visible" in SQS


SQS - Message Visibility Timeout
-If a message is not processed within the
 visibility timeout, it will be processed twice

-A consumer could call the ChangeMessageVisibility
 API to get more time

-If visibility timeout is high (hours),
 and consumer crashes, re-processing will
 take time

-If visibility timeout is too low (seconds), 
 we may get duplicates




SQS- Dead Letter Queues

Amazon SQS - Dead Letter Queues
-If a consumer fails to process a message
 within the Visibility Timeout...
 the message goes back to the queue!

-We can set a threshold of how many times a message
 can go back to the queue

-After the MaximumRecieves threshold is exceeded
 the message goes into a dead letter queue (DLQ)


-Useful for debugging

-Make sure to process the messages in the DLQ before
 they expire:
 -Good to set a retention of 14 days in the DLQ




SQS - Delay Queues

Amazon SQS - Delay Queue
-Delay a message (consumers don't see it immediately) up to 
 15 minutes

-Default is 0 seconds (message is available right away)

-Can set a default at queue level

-Can override the default on send using the DelaySeconds
 parameter


Create a queue.
Delivery Delay.



SQS - Certified Developer concepts

Amazon SQS - Long Polling
-When a consumer requests messages from the
 queue, it can optionally "wait" for messages to
 arrive if there are none in the queue

-This is called Long Polling

-LongPolling decreases the number of API calls
 made to SQS while increasing the efficiency and
 latency of your application

-The wait time can be between 1 sec to 20 sec
 (20 sec preferable)

-Long Polling is preferable to Short Polling

-Long polling can be enabled at the queue level
 or at the API level using WaitTimeSeconds


SQS Extended Client
-Message size limit is 256KB, how to send
 large messages e.g. 1 GB?

-Using the SQS Extended Client (Java Library)

Producer want to send a large message
SQS will contain small messages.
Consumer reads a large message from S3 bucket.
Sends a small pointer to the videofile into the 
SQS bucket.


SQS - Must know API
-CreateQueue (MessageRetentionPeriod), DeleteQueue
-PurgeQueue: delete all the messages in queue
-SendMessage(DelaySeconds), RecieveMessage, DeleteMessage
-RecieveMessageWaitTimeSeconds: Long Polling
-ChangeMessageVisibility: change the message timeout

-Batch APIs for SendMessage, DeleteMessage, 
 ChangeMessageVisibility helps decrease your costs




SQS - FIFO Queues

Amazon SQS - FIFO Queue
-FIFO = First In First Out (ordering of messages in the queue)
-Limited throughput: 300 msg/s without batching, 3000 msg/s
 with

-Exactly-once send capability (by removing duplicates)

-Messages are processed in order by the consumer






SQS - FIFO Queues Advanced

SQS FIFO - Deduplication
-De-duplication interval is 5 minutes
-Two de-duplication methods:
 -Content-based deduplication: will do SHA-256 hash of the
   							   message body
 -Explicity provide a Message Deduplication ID


SQS FIFO - Message Grouping
-If you specify the same value of MessageGroupID in an
 SQS FIFO queue, you can only have one consumer,
 and all the messages are in order

-To get ordering at the level of a subset of messages, specify
 different values for MessageGroupID

 -Messages that share a common Message Group ID
  will be in order within the group

 -Each Group ID can have different consumer
  (parallel processing!)

 -Ordering across groups is not guaranteed





Amazon SNS - Overview

Amazon SNS
-What if you want to send one message to many recievers?

Pub / Sub pattern: Topic will send to an SNS topic.

-The "event producer" only sends to one SNS topic
-As many "event recievers" (subsripttions) as
 we want to listen to the SNS topic notifications

-Each subsrcriber to the topic will get all the messages
 (note: new feature to filter messages)

-Up to 10.000.000 subsrciptions per topic
-100.000 topics limit
-Subsrcribers can be:
 -SQS
 -HTTP /HTTPS (with delivery retries - how many times)
 -Lambda
 -Emails
 -SMS messages
 -Mobile Notifications


SNS integrates with a lot of AWS services
-Many AWS services can send data directly to SNS for
 notifications

-CloudWatch (for alarms)
-Auto Scaling Groups notifications
-Amazon S3 (on bucket events)
-CloudFormation (upon state changes => failed to build, etc)
-Etc...

AWS SNS - How to publish
-Topic Publish (using the SDK) 
 -Create a topic
 -Create a subsrciption (or many)
 -Publish to the topic

-Direct Publish (for mobile apps SDK)
 -Create a platform application
 -Create a platform endpoint
 -Publish to the platform endpoint
 -Works with Google GCM, Apple APNS, Amazon ADM...


Amazon SNS - Security
-Encryption:
 -In-flight encryption using HTTPS API
 -At-rest encryption using KMS keys
 -Client-side encryption if the client wants to perform
  encryption/decryption itself

-Access Controls: IAM policies to regulate access to the
 SNS API
 
-SNS Access Policies (similar to S3 bucket policies)
 -Useful for cross-account access to SNS topics
 -Useful for allowing other services ( S3...) to
  write to an SNS topic





SNS - Hands On
Create a topic.
Create a subsrciption.
Publish a message.



SNS and SQS - Fan Out Pattern

SNS + SQS: Fan out

-Push once in SNS, recieve in all SQS queues that are
 subsrcribers that are subsrcribers

-Fully decoupled, no data loss

-SQS allows for: data persistence, delayed processing
                 and retries of work

-Ability to add more SQS subsrcribers over time

-Make sure your SQS queue access policy allows for SNS
 to write

-SNS cannot send messages to SQS FIFO queues
 (AWS limitation)



Send first an SNS topic and thereafter deliver it to the
other SQS queues.


Application: S3 Events to multiple queues

-For the same combination of: event type (e.g object create)
 and prefix (e.g. images/) you can only have one S3 event
 rule

-If you want to send the same S3 event to many SQS queues,
 use fan-out



You have your object created from the Amazon S3 to the
SNS Topic to other SQS queues




AWS Kinesis Overview
-Kinesis is a managed alternative to Apache Kafka
-Great for application logs, metrics, IoT, clickstreams
-Great for "real-time" big data
-Great for streaming processing frameworks (Spark,Nifi,etc...)
-Data is automatically replicated to 3 AZ

-Kinesis Streams: low latency streaming ingest at scale
-Kinesis Analytics: perform real-time analytics on streams
 using SQL

-Kinesis Firehose: load streams into S3, Redshift, 
				   ElasticSearch...


Kinesis 

Kinesis in the middle.
Kinesis Analytics wants to perform analytics on these data.
Kinesis Firehose put them into a S3 bucket or amazon
Redshift.


Kinesis Streams Overview
-Streams are divided in ordered Shards / Partitions
-Data retention is 1 day by default, can go up to 7 days
-Ability to reprocess / replay data
-Multiple applications can consume the same stream
-Real-time processing with scale of throughput
-Once data is inserted in Kinesis, it can't be deleted
 (immutability)


Kinesis Streams Shards
-One stream is made of many different shards
-1MB/s or 1000 messages/s at write PER SHARD
-2MB/s at read PER SHARD
-Biling is per shard provisioned, can have as many shards as
 you want

-Batching available or per message calls
-The number of shards can evolve over time(reshard / merge)
-Records are ordered per shard


AWS Kinesis API - Put records
-PutRecord API + Partition key that gets hashed
-The same key goes to the same partition
 (helps with ordering for a specific key)
-Messages sent get a "sequence number"
-Choose a partition key that is highly
 distributed(helps prevent "hot partition")

 -user_id if many users
 -Not country_id if 90% of the users are in one country

-Use Batching with PutRecords to reduce costs and
 increase throughput

-ProvisionedThroughputExceeded if we go over the limits

-Can use CLI,AWS,SDK, or producer libraries from
 various frameworks



Producers we reshard and merge.


AWS Kinesis API - Exceptions
-ProvisionedThroughputExceeded Exceptions
 -Happens when sending more data
  (exceeding MB/s or TPS for any shard)

 -Make sure you don't have a hot shard
  (such as your partition key is bad and too much data gets to 
   that partition)


-Solution:
 -Retries with backoff
 -Increase shards (scaling)
 -Ensure your partition key is a good one


AWS Kinesis API - Consumers
-Can use a normal consumer
 (CLI, SDK, etc...)

-Can use Kinesis Client Library
 (in Java, Node,Python, Ruby, .Net)

  -KCL uses DynamoDB to track other
   workers and share the work amongst shards

  -KCL uses DynamoDB to track other workers
   and share the work amongst shards





AWS Kinesis Hands On
We can have different cases.
Create a data stream.
How many time we want's it's capacity.
Send data with KCL producer library.
Retain the data-flow.

Go to the monitoring.
We have all the limits.

list streams
describe streams
put-record.
partition-key.
shard-iterator.



AWS Kinesis KCL

Kinesis KCL in Depth

-Kinesis Client Library (KCL) is Java library that
 helps read record from a Kinesis Streams with
 distributed applications sharing the read workload

-Rule: each shard is be read by only one KCL instance

-Means 4 shards = max 4 KCL instances

-Means 6 shards = max 6 KCL instances

-Progress is checkpointed into DynamoDB (need IAM access)

-KCL can run on EC2, Elastic Beanstalk, on
 Premise Application


-Records are read in order at the shard level


KCL Example: 4 shards
Two KCL apps are reading from two shards.

KCL Example: 4 shards, scaling KCL app
At maximum throughput.
Shard splitting.

Checking progress in DynamoDB as a checkpoint.




Kinesis Security, Firehose and Analytics

Kinesis Security
-Control access / authorization using IAM policies
-Encryption in flight using HTTPS endpoints
-Encryption at rest using KMS
-Possibility to encrypt / decrypt data client side (harder)
-VPC Endpoints available for Kinesis to access within VPC

AWS Kinesis Data Analytics
-Perform real-time analytics on Kinesis Streams using SQL
-Kinesis Data Analytics:
 -Auto Scaling
 -Managed: no servers to provision
 -Continous: real time

-Pay for actual consumption rate
-Can create streams out of the real-time queries


AWS Kinesis Firehose
-Fully Managed Service, no administration
-Near Real Time (60 seconds latency)
-Load data into Redshift / Amazon S3 / ElasticSearch / Splunk
-Automatic Scaling
-Support many data format (pay for conversion)
-Pay for the amount of data going through Firehose



SQS vs SNS vs Kinesis
SQS:
-Consumer "pull data"
-Data is deleted after being consumed
-Can have as many workers(consumers) as we want
-No need to provision throughput
-No ordering gurantee (except FIFO queues)
-Individual message delay capability


SNS:
-Push data to many subsrcribers
-Up to 10.000.000 subsrcribers
-Data is not persisted(lost if not delivered)
-Pub / Sub
-Up to 100.000 topics
-No need to provision throughput
-Intergrates with SQS for fan-out
 architecture pattern


Kinesis:
-Consumers "pull data"
-As many consumers as we want
-Possibility to replay data
-Meant for real-time big data, analytics and ETL
-Ordering at the shared level
-Data expires after X days
-Must provision throughput




Data Ordering for Kinesis vs SQS FIFO

Ordering data into Kinesis
-Imagine you have 100 trucks
 (truck_1,truck_2,...,truck_100) on
 the road sending their GPS positions
 reguraly into AWS


-You want to consume the data in order for each truck,
 so that you can track their movement accurately

-How should you send that data into Kinesis?


-Answer: send using a "Partition Key"
         value of the "truck_id"

-The same key will always go to the same shard



Ordering data into SQS
-For SQS standard, there is no ordering
-For SQS FIFO, if you don't use a Group ID, messages
 are consumed in the order they are sent, with only
 one consumer

-You want to scale the number of consumers,
 but you want messages to be "grouped"
 when they are related to each other

-Then you use a Group ID (similar to Partition Key in Kinesis)


Kinesis vs SQS ordering
-Let's assume 100 trucks, 5 trucks shards, I SQS FIFO
-Kinesis Data Streams:
 -On average you'll have 20 trucks per shard
 -Trucks will have their data ordered within each shard
 -The maximum amount of consumers in parallel we can have is 5
 -Can recieve up to 5 MB/s of data

-SQS FIFO
 -You only have one SQS FIFO queue
 -You will have 100 Group ID
 -You can have up to 100 consumers (due to the 100 Group ID)
 -You have up to 300 messages per second 
  (or 3000 if using batching)





Quiz 17: Messaging and Integration Quiz

Question 1:
You are preparing for the biggest day of sale of the year, where your traffic will increase by 100x. You have already setup SQS standard queue. What should you do?



Answer:
	Do nothing, SQS scales automatically



Question 2:
You would like messages to be processed by SQS consumers only after 5 minutes. What should you do?

Answer:
   Increase the DelaySeconds parameters


Question 3:
Your consumers poll 10 messages at a time and finish processing them in 1 minute. You notice that your messages are processed twice, as other consumers also receive the messages. What should you do?

Answer:
	Increase the Visibility Timeout


Question 4:
One message keeps on being processed and makes your consumers crash one by one. That message has a bad format and you'd like to get rid of it automatically if that happens. How can you implement this?

Answer:
    Implement a DLQ with redrive police



Question 5:
Your SQS costs are extremely high. Upon closer look, you notice that your consumers are polling SQS too often and getting empty data as a result. What should you do

Answer:
   Enable Long Polling


Question 6:
You'd like your messages to be processed exactly once and in order. Which do you need?

Answer:
    SQS FIFO Queue



Question 7:
You want to send messages of 1 MB to SQS. You need to

Answer:
   Use the SQS Extended Client library



Question 8:
You'd like to send a message to 3 different applications all using SQS. You should


Answer:
  Use SNS + SQS Fan Out pattern



Question 9:
You have a Kinesis stream usually receiving 5MB/s of data and sending out 8 MB/s of data. You have provisioned 6 shards. Some days, your traffic spikes up to 2 times and you get a throughput exception. You should

Answer:
    Add more shards


Question 10:
You are sending a clickstream for your users navigating your website, all the way to Kinesis. It seems that the users data is not ordered in Kinesis, and the data for one individual user is spread across many shards. How to fix that problem?


Answer:
   You should use a partition key that represents
   the indentity of the user


Question 11:
You intermittently get a ProvisionedThroughputExceeded Exception in your producing applications. You should

Answer:
   Use exponential backoff on retries


Question 12:
We'd like to perform real time analytics on streams of data. The most appropriate product will be

Answer:
	Kinesis


Question 13:
We'd like for our big data to be loaded near real time to S3 or Redshift. We'd like to convert the data along the way. What should we use?

Answer:
	Kinesis Streams + Kinesis Firehose




Question 14:
You want to send email notifications to your users. You should use

Answer:
   SNS





Question 15:
Which SQS FIFO message attribute allows two messages to be processed in order?

Answer:
 MessageGroupID



Question 16:
Which SQS FIFO message attribute allows two messages to be de-duplicated ?

Answer:
  MessageDedupicationId



 Question 17:
One of your Kinesis Stream is experiencing increased traffic due to a sale day. Therefore your Kinesis Administrator has split shards and thus you went from having 6 shards to having 10 shards in your Kinesis Stream. Your consuming application is running a KCL-based application on EC2 instances. What is the maximum number of EC2 instances that can be deployed to process the shards?

Answer:
   10

 In KCL, you can have a maximum of EC2 instances running in parallel equal to the number of shards in your Kinesis Stream.



 Question 18:
If you currently have 10 active group messages (defined by GroupID) in your SQS FIFO queues, how many consumers can consume simultaneously?

Answer:
 10

you can have as many consumers as GroupID for your FIFO queues



   


